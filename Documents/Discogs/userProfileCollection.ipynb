{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Dictionary created in order to fill in empty rows in the Dataframe when the user profile queried does not exist\n",
    "\n",
    "exc = {\n",
    "    'num_collection': np.nan, \n",
    "    'seller_rating_stars': np.nan, \n",
    "    'buyer_num_ratings': np.nan,\n",
    "    'collection_folders_url': np.nan, \n",
    "    'banner_url': np.nan, \n",
    "    'home_page': np.nan, \n",
    "    'avatar_url': np.nan,\n",
    "    'rating_avg': np.nan,\n",
    "    'name': np.nan, \n",
    "    'buyer_rating': np.nan, \n",
    "    'releases_rated': np.nan,\n",
    "    'seller_num_ratings': np.nan,\n",
    "    'num_for_sale': np.nan, \n",
    "    'curr_abbr': np.nan, \n",
    "    'profile': np.nan, \n",
    "    'registered': np.nan, \n",
    "    'location': np.nan,\n",
    "    'inventory_url': np.nan, \n",
    "    'rank': np.nan,\n",
    "    'num_lists': np.nan,\n",
    "    'num_pending': np.nan,\n",
    "    'collection_fields_url': np.nan,\n",
    "    'buyer_rating_stars': np.nan,\n",
    "    'wantlist_url': np.nan, \n",
    "    'uri': np.nan,\n",
    "    'seller_rating': np.nan, \n",
    "    'id': np.nan,\n",
    "    'releases_contributed': np.nan,\n",
    "    'resource_url': np.nan, \n",
    "    'username': np.nan, \n",
    "    'num_wantlist': np.nan, \n",
    "    'message': 'Request Timeout',\n",
    "}\n",
    "\n",
    "# creation of a Dataframe where data is parsed to\n",
    "\n",
    "col = ['num_collection', 'seller_rating_stars', 'buyer_num_ratings',\n",
    "       'collection_folders_url', 'banner_url', 'home_page', 'avatar_url',\n",
    "       'rating_avg', 'name', 'buyer_rating', 'releases_rated',\n",
    "       'seller_num_ratings', 'num_for_sale', 'curr_abbr', 'profile',\n",
    "       'registered', 'location', 'inventory_url', 'rank', 'num_lists',\n",
    "       'num_pending', 'collection_fields_url', 'buyer_rating_stars',\n",
    "       'wantlist_url', 'uri', 'seller_rating', 'id', 'releases_contributed',\n",
    "       'resource_url', 'username', 'num_wantlist', 'message']\n",
    "\n",
    "df1= pd.DataFrame(columns = col)\n",
    "df1.to_csv('export1.csv')\n",
    "\n",
    "# creation of a Dataframe to keep track of user profiles that were not queried properly (time out or profile does not exist)\n",
    "\n",
    "dftimeout1 = pd.DataFrame(columns = ['url'])\n",
    "\n",
    "# definition of function to get user names, query their profile with the API and parse results in the Dataframe\n",
    "\n",
    "def get_users(page):\n",
    "    \n",
    "    # creation of the username list scraping from the contributors page (discogs.com/contributors)\n",
    "    \n",
    "    list_users = []\n",
    "    url = 'https://www.discogs.com/stats/contributors?page=%s' % page\n",
    "    try: \n",
    "        r = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(r, 'html.parser')\n",
    "        letters = soup.find_all(\"a\", class_='linked_username')\n",
    "        for i in range(0,len(letters)):\n",
    "            list_users.append(['https://api.discogs.com'+letters[i]['href'].replace('user','users'),page])\n",
    "        \n",
    "        # querying all the user names collected\n",
    "        \n",
    "        for j in range(0, len(list_users)):\n",
    "            url = list_users[j][0]\n",
    "            headers = {\n",
    "            # Authorisation details can be found on discogs.com/developers/\n",
    "                'Authorization': 'Discogs key=[key], secret=[secret]',\n",
    "            }\n",
    "            try:\n",
    "                r = requests.get(url, headers = headers)\n",
    "                store = json.loads(r.text)\n",
    "                \n",
    "            # exception for timeout or value errors of the API call\n",
    "            \n",
    "            except (requests.ConnectionError, ValueError): \n",
    "                store = exc\n",
    "                print('Request Timeout')\n",
    "            print(list_users[j][0])\n",
    "            \n",
    "            # parsing the data in the Dataframe\n",
    "            \n",
    "            for l in range(0,len(list(store.keys()))):\n",
    "                df1.loc[list_users[j][0],list(store.keys())[l]] = list(store.values())[l]\n",
    "            print(df1.loc[list_users[j][0],'username'], df1.loc[list_users[j][0],'message'])\n",
    "        print(\"%s users added from page %s. Total is at %s or %s percent\" % (len(letters), page, page*50, (page*50/364421)*100))\n",
    "    \n",
    "    # excption for time out error on the scraping \n",
    "    \n",
    "    except urllib.error.URLError: \n",
    "        print('URL Timeout')\n",
    "        dftimeout1.loc[len(dftimeout1)] = url\n",
    "        dftimeout1.to_csv('timeout1.csv')\n",
    "\n",
    "\n",
    "# defining the range where the data is scraped from on discogs.com/contributors\n",
    "\n",
    "for i in range (1,2000): \n",
    "    df1.from_csv('export1.csv')\n",
    "    get_users(i)\n",
    "    df1.to_csv('export1.csv')\n",
    "    time.sleep(20) \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
